{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764702df-983f-41a3-b7b0-6bc11ee12e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to your dataset directory\n",
    "data_dir = r'C:\\Users\\prajw\\OneDrive\\Desktop\\skin_burn_classification\\data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "# Print the paths to verify\n",
    "print(f\"Training directory: {train_dir}\")\n",
    "print(f\"Validation directory: {val_dir}\")\n",
    "\n",
    "# Parameters for image preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 32 using val_datagen generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Convert generators to datasets and apply repeat()\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, train_generator.num_classes), dtype=tf.float32)\n",
    "    )\n",
    ").repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, val_generator.num_classes), dtype=tf.float32)\n",
    "    )\n",
    ").repeat()\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom top layers for your classification task with regularization\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return float(lr)\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Model checkpoint\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model and capture the history\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=25,  # Increased epochs for better training\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_generator),\n",
    "    shuffle=True,  # Shuffle the data at the beginning of each epoch\n",
    "    callbacks=[early_stopping, lr_callback, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Check if the model directory exists\n",
    "model_dir = os.path.join(data_dir, 'model')\n",
    "if os.path.exists(model_dir):\n",
    "    # Rename the existing model directory\n",
    "    new_model_dir = os.path.join(data_dir, 'model_old')\n",
    "    if os.path.exists(new_model_dir):\n",
    "        shutil.rmtree(new_model_dir)\n",
    "    os.rename(model_dir, new_model_dir)\n",
    "\n",
    "# Create the new model directory\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, 'skin_burn_classification_model.keras')\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
